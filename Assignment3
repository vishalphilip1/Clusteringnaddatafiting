"""
Created on Wed May 10 08:30:31 2023.

@author: acer
"""


import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
import scipy.optimize as opt
import numpy as np


def read_data(filename):
    data = pd.read_excel(filename)
    data.dropna(how='all', inplace=True)
    data = data[~data.isin(['..']).any(axis=1)]
    return data

def transpose_data(data):
    transposed_data = data.transpose()
    transposed_data.dropna(inplace=True)
    return transposed_data

def normalize_data(data):
    scaler = MinMaxScaler()
    normalized_data = pd.DataFrame(
        scaler.fit_transform(data), columns=data.columns)
    return normalized_data

def cluster_data(data, features, n_clusters):
    x = data[features]
    kmeans = KMeans(n_clusters=n_clusters)
    kmeans.fit(x)
    identified_clusters = kmeans.predict(x)
    centroids = kmeans.cluster_centers_  # Get the centroids of each cluster
    data_with_clusters = data.copy()
    data_with_clusters['Cluster'] = identified_clusters
    return data_with_clusters, centroids


# Read and preprocess data for 1990
readdata1990 = read_data(
    'P_Data_Extract_From_World_Development_Indicators1990.xlsx')

transposed_data1990 = transpose_data(readdata1990)

filtered_dfc1990 = readdata1990[
    readdata1990['Series Code'] == 'EN.ATM.CO2E.KT']
filtered_dfg1990 = readdata1990[
    readdata1990['Series Code'] == 'EN.ATM.GHGT.KT.CE']
filtered_dfc1990.drop(['Series Name', 'Series Code',
                       'Country Code'], axis=1, inplace=True)
filtered_dfc1990.set_index('Country Name', inplace=True)
filtered_dfc1990.columns = ['carbon_1990']
filtered_dfc1990.dropna(inplace=True)
filtered_dfg1990.drop(['Series Name',
                       'Series Code', 'Country Code'], axis=1, inplace=True)
filtered_dfg1990.set_index('Country Name', inplace=True)
filtered_dfg1990.columns = ['emission_1990']
filtered_dfg1990.dropna(inplace=True)
data2 = pd.concat([filtered_dfc1990, filtered_dfg1990], axis=1)
data2.dropna(inplace=True)

# Read and preprocess data for 2019
readdata2019 = read_data(
    'P_Data_Extract_From_World_Development_Indicators.xlsx')
filtered_dfc2019 = readdata2019[readdata2019[
    'Series Code'] == 'EN.ATM.CO2E.KT']
filtered_dfg2019 = readdata2019[readdata2019[
    'Series Code'] == 'EN.ATM.GHGT.KT.CE']
carbon_2019 = filtered_dfc2019['2019 [YR2019]']
greenhouse_2019 = filtered_dfg2019['2019 [YR2019]']
country_names2019 = filtered_dfc2019['Country Name']
data1 = pd.DataFrame({'carbon_2019': carbon_2019.values,
                      'greenhouse_2019': greenhouse_2019.values,
                      'Country Name': country_names2019.values})
data1.dropna(subset=['carbon_2019', 'greenhouse_2019',
                     'Country Name'], inplace=True)

# Normalize the data
normalized_data1 = normalize_data(data1[['carbon_2019', 'greenhouse_2019']])
normalized_data2 = normalize_data(data2[['carbon_1990', 'emission_1990']])

# Cluster the data and obtain centroids
data_with_clusters1, centroids1 = cluster_data(data1, ['carbon_2019',
                                                       'greenhouse_2019'], 3)
data_with_clusters2, centroids2 = cluster_data(data2, ['carbon_1990',
                                                       'emission_1990'], 3)

# Plot the scatter plot with clusters for 2019 data

plt.scatter(
    data_with_clusters1[data_with_clusters1['Cluster'] == 0]['carbon_2019'],
    data_with_clusters1[data_with_clusters1
                        ['Cluster'] == 0]['greenhouse_2019'],
     s=100, label='Cluster 0')
plt.scatter(
    data_with_clusters1[data_with_clusters1['Cluster'] == 1]['carbon_2019'],
    data_with_clusters1[data_with_clusters1
                        ['Cluster'] == 1]['greenhouse_2019'],
    s=100, label='Cluster 1')
plt.scatter(data_with_clusters1[
    data_with_clusters1['Cluster'] == 2]['carbon_2019'],
    data_with_clusters1[data_with_clusters1
                        ['Cluster'] == 2]['greenhouse_2019'],
     s=100, label='Cluster 2')
plt.legend()
# Plot centroids
plt.scatter(centroids1[:, 0], centroids1[:, 1], marker='*', s=50, c='black',
            label='Centroids')  # Plot centroids
plt.title('K-Means Clustering for the Year 2019')
plt.xlabel('Carbon Emission')
plt.ylabel('Greenhouse House Emission')
plt.legend()
plt.show()

# Plot the scatter plot with clusters for 1990 data
# Plot the scatter plot with clusters for 1990 data
plt.scatter(data_with_clusters2[data_with_clusters2
                                ['Cluster'] == 0]['carbon_1990'],
            data_with_clusters2[data_with_clusters2['Cluster'] == 0]
            ['emission_1990'],
            label='Cluster 0', s=100)

plt.scatter(data_with_clusters2[data_with_clusters2['Cluster'] == 1]
            ['carbon_1990'],
            data_with_clusters2[data_with_clusters2
                                ['Cluster'] == 1]['emission_1990'],
            label='Cluster 1', s=100)

plt.scatter(data_with_clusters2[data_with_clusters2
                                ['Cluster'] == 2]['carbon_1990'],
            data_with_clusters2[data_with_clusters2
                                ['Cluster'] == 2]['emission_1990'],
            label='Cluster 2', s=100)

# Plot centroids
plt.scatter(centroids2[:, 0], centroids2[:, 1], marker='*', s=50, c='black',
            label='Centroids')

plt.title('K-Means Clustering for the Year 1990')
plt.xlabel('Carbon Emission')
plt.ylabel('GreehHouse Emission')

# Add legend
plt.legend()

plt.show()

# Filter data points for cluster 1 in 2019 data
cluster1_data_20190 = data_with_clusters1[data_with_clusters1['Cluster'] == 0]
cluster1_data_20191 = data_with_clusters1[data_with_clusters1['Cluster'] == 1]
cluster1_data_20192 = data_with_clusters1[data_with_clusters1['Cluster'] == 2]
print(cluster1_data_20190)
print(cluster1_data_20191)
print(cluster1_data_20192)

# Filter data points for cluster 1 in 2019 data
cluster2_data_20190 = data_with_clusters2[data_with_clusters2['Cluster'] == 0]
cluster2_data_20191 = data_with_clusters2[data_with_clusters2['Cluster'] == 1]
cluster2_data_20192 = data_with_clusters2[data_with_clusters2['Cluster'] == 2]

print(cluster2_data_20190)
print(cluster2_data_20191)
print(cluster2_data_20192)


readdata3 = pd.read_excel(
    'P_Data_Extract_From_World_Development_Indicatorsuk.xlsx')

readdata3 = readdata3.drop([1, 2, 3, 4, 5])


readdata3 = readdata3.T
# Assuming your DataFrame is named 'emissions_df'
readdata3.reset_index(inplace=True)


readdata3 = readdata3.drop([1, 2, 3, ])


# Reset the index
readdata3 = readdata3.reset_index(drop=True)


# Delete rows with index 1, 2, and 3
readdata3 = readdata3.drop([1, 2, 3])

# Reset the index
readdata3 = readdata3.reset_index(drop=True)


readdata3 = readdata3.set_axis(readdata3.iloc[0], axis=1)
readdata3 = readdata3[1:]


readdata3 = readdata3.rename(columns={
    'Total greenhouse gas emissions (kt of CO2 equivalent)': 'emission'})
readdata3 = readdata3.rename(columns={'Series Name': 'Year'})

readdata3.plot("Year", "emission")
plt.xlabel('Year')
plt.ylabel('Greenhouse Emission')
plt.title('Total Green House Emission of UK ')
plt.show()


def exponential(t, n0, g):
    # Calculates exponential function with scale factor n0 and growth rate g
    t = t - 1990
    f = n0 * np.exp(g * t)
    return f


print(type(readdata3["Year"].iloc[1]))
readdata3["Year"] = pd.to_numeric(readdata3["Year"])
print(type(readdata3["Year"].iloc[1]))
param, covar = opt.curve_fit(exponential, readdata3["Year"],
                             readdata3["emission"], p0=(1.2e12, 0.03))
print("Year", param[0]/1e9)
print("Year", param[1])

# Convert the emission column to a NumPy array
emission_array = readdata3["emission"].to_numpy()

# Define the exponential function
#def exponential(t, n0, g):
#    t = t - 1990
 #   f = n0 * np.exp(g * t)
 #   return f

plt.figure()
readdata3["fit"] = exponential(readdata3["Year"], *param)
readdata3.plot("Year", ["emission", "fit"])
plt.title(" Data fiting with n0 * np.exp(g * t)")
plt.xlabel('Year')
plt.ylabel('Greenhouse Emission')
plt.show()

def logistic(t, n0, g, t0):
    """Calculates the logistic function with 
    scale factor n0 and growth rate g"""
    f = n0 / (1 + np.exp(-g*(t - t0)))
    return f


param, covar = opt.curve_fit(logistic,
                             readdata3["Year"], readdata3["emission"],
                             p0=(1.2e12, 0.03, 1990.0), maxfev=100000)
sigma = np.sqrt(np.diag(covar))
readdata3["fit"] = logistic(readdata3["Year"], *param)
readdata3.plot("Year", ["emission", "fit"])
plt.title("Data fiting with n0 / (1 + np.exp(-g*(t - t0)))")
plt.xlabel('Year')
plt.ylabel('Greenhouse Emission')
plt.show()

print("turning point:", param[2], "+/-", sigma[2])
print("emission at turning point:", param[0]/1e9, "+/-", sigma[0]/1e9)
print("emission rate:", param[1], "+/-", sigma[1])

# predicting the years
year = np.arange(1990, 2030)
forecast = logistic(year, *param)
plt.figure()
plt.plot(readdata3["Year"], readdata3["emission"], label="Greenhouse Emission")
plt.plot(year, forecast, label="forecast")
plt.title('Prediction of Green House Emission from 1990 to 2030')
plt.xlabel("Year")
plt.ylabel("Green House Emission")
plt.legend()
plt.show()

import err_ranges as err

low, up = err.err_ranges(year, logistic, param, sigma)
plt.figure()
plt.plot(readdata3["Year"], readdata3["emission"], label="Greenhouse Emission")
plt.plot(year, forecast, label="forecast")
plt.fill_between(year, low, up, color="greenyellow", alpha=0.7)
plt.title('Best fiting functiong including confidence range')
plt.xlabel("Year")
plt.ylabel("Green House Emission")
plt.legend()
plt.show()
